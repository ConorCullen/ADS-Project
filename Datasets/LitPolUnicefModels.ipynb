{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imported Packages and Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from zipfile import ZipFile\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from IPython import display\n",
    "from time import sleep\n",
    "import scipy.stats  as stats\n",
    "from statistics import mean,mode,stdev\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import sklearn\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.cluster import KMeans\n",
    "from itertools import permutations\n",
    "import itertools\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import mixture\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore')\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "import scipy.stats as ss\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Literacy and numeracy dataset, define list of countries, years and features in dataset\n",
    "File = pd.read_csv('LiteracyNumeracyDataset2.csv')\n",
    "country = 'Country'\n",
    "countries = File.Country.unique()\n",
    "Year = ['2013','2014','2015','2016','2017','2018']\n",
    "Indicator = File.Indicator.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import political gender balance dataset, and defining features and years in dataset\n",
    "FileGen = pd.read_csv('PoliticalGenderBalanceDataset2.csv')\n",
    "Year = ['2013','2014','2015','2016','2017','2018']\n",
    "IndicatorGen = FileGen.Indicator.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import unicef dataset 1 (Financial inclusion, family demand, labour participation rates)\n",
    "FileUnicef1 = pd.read_csv('UnicefDatasets1.csv',encoding = \"ISO-8859-1\")\n",
    "IndicatorUnicef1 = list(FileUnicef1.columns.values[5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to rearrange dataframe\n",
    "def rearrange_dataframe(df, indicator_name):\n",
    "    #years = [c for c in df.columns if c[0] == '1' or c[0] == '2']\n",
    "    years = Year\n",
    "    df = df.loc[df['Indicator'] == indicator_name]\n",
    "    df = pd.melt(df[[country] + years], id_vars=country, var_name='year')\n",
    "    ## https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.melt.html\n",
    "    df.rename(columns={'value': indicator_name}, inplace=True)\n",
    "    df.set_index(['year', country], inplace=True)\n",
    "    return df\n",
    "\n",
    "# function to get most recent value of attribute of each country and create dataset\n",
    "def get_recent_value(df,indicator_name):\n",
    "    data = pd.DataFrame(columns = ['Country',indicator_name])\n",
    "    years = Year\n",
    "    df = df.loc[df['Indicator'] == indicator_name]\n",
    "    #List = []\n",
    "    for i in range(len(countries)):\n",
    "        ValueList = []\n",
    "        num = 0\n",
    "        ValueList.append(countries[i])\n",
    "        ValueList.append(np.nan)\n",
    "        #ValueList.append('Nan')\n",
    "        for j in range(len(years)-1,-1,-1):\n",
    "            q = df[df['Country'] == countries[i]]\n",
    "            a = q.loc[:,years[j]]\n",
    "            #if (str(a.item())!='nan') and (num == 0):\n",
    "            if (str(a.item()) != str(np.nan)) and (num == 0):\n",
    "                ValueList[1] = float(a.item())\n",
    "                num = 1\n",
    "        data = data.append({'Country': ValueList[0], indicator_name: ValueList[1]}, ignore_index=True)\n",
    "    return data\n",
    "\n",
    "# function to find correlations and significance between features of dataset\n",
    "def Correlation_features(X,IndicatorList):\n",
    "    CorrMatrix = np.zeros((len(IndicatorList),len(IndicatorList)))\n",
    "    SigMatrix = np.zeros((len(IndicatorList),len(IndicatorList)))\n",
    "    for i in range(len(IndicatorList)):\n",
    "        FirstInd = X[:,i]\n",
    "        for j in range(len(IndicatorList)):\n",
    "            if i == j:\n",
    "                CorrMatrix[i,j] = 1\n",
    "                continue\n",
    "            else:\n",
    "                SecondInd = X[:,j]\n",
    "                # Correlation\n",
    "                correlation = pearsonr(FirstInd,SecondInd)\n",
    "                CorrMatrix[i,j] = correlation[0]\n",
    "                # Significance\n",
    "                SigMatrix[i,j] = correlation[1]\n",
    "    return CorrMatrix, SigMatrix\n",
    "\n",
    "# function that prints heatmap of correlations\n",
    "def correlation_heatmap(CorrMatrix):\n",
    "    %matplotlib qt\n",
    "    ax = sns.heatmap(CorrMatrix, vmin=-1, vmax=1,cmap='cool')\n",
    "    return\n",
    "\n",
    "# function that prints moderate correlations that are significant\n",
    "def significant_correlations(CorrMatrix,SigMatrix,IndicatorList):\n",
    "    ModulusMatrix = abs(CorrMatrix)\n",
    "    a = 0\n",
    "    print(\"\\033[1m\" + \"Indicators with a moderate correlation (>0.5) and are significant at a 5% level of significance:\"\n",
    "          + \"\\033[0;0m\")\n",
    "    for i in range(len(IndicatorList)):\n",
    "        for j in range(len(IndicatorList)):\n",
    "            if i == j:\n",
    "                continue\n",
    "            if (ModulusMatrix[i,j] > 0.5) and (SigMatrix[i,j] < 0.05):\n",
    "                a = a + 1\n",
    "                print(str(IndicatorList[i]) + \" V.S. \" + str(IndicatorList[j]) + \" ---> \" + str(CorrMatrix[i,j]) + \"\\n\")\n",
    "    if a == 0:\n",
    "        print(\"None\")\n",
    "    return\n",
    "\n",
    "# function that plots indicator over time\n",
    "def plot_indicator(df, indicator_name):\n",
    "    fig, ax = plt.subplots(figsize=[15 ,10])\n",
    "    for label, dfi in df.groupby(level=1):\n",
    "        dfi[indicator].plot(ax=ax, label=label)\n",
    "    plt.legend()\n",
    "    ax.set_ylabel(indicator)\n",
    "    ax.set_xticklabels(df1c.index.levels[0].values)\n",
    "    ax.set_xlabel('year')\n",
    "    return\n",
    "\n",
    "# function that assigns a group colour to each datapoint based on label (GNI or Region)\n",
    "def get_regions_and_gni(File,FileUnicef1,r,g,h,d,cl,attribute):\n",
    "    RegionsList = []\n",
    "    REGIONS = []\n",
    "    gniList = []\n",
    "    GNI = []\n",
    "    colourList = []\n",
    "    COLOUR = []\n",
    "    happyList = []\n",
    "    HAPPY = []\n",
    "    devList = []\n",
    "    DEV = []\n",
    "    for k in range(len(countries)):\n",
    "        Data = File.loc[File['Country'] == countries[k]]\n",
    "        RegionName = Data['Region'].unique()\n",
    "        gniName = Data['GNI'].unique()\n",
    "        RegionsList.extend(RegionName)\n",
    "        gniList.extend(gniName)\n",
    "        Data2 = FileUnicef1.loc[FileUnicef1['Country'] == countries[k]]\n",
    "        happyName = Data2['HPI_Class'].unique()\n",
    "        happyList.extend(happyName)\n",
    "        devName = Data2['Development'].unique()\n",
    "        devList.extend(devName)\n",
    "        for i in range(len(r)):\n",
    "            if (str(r[i]) == str(RegionName)) and (attribute == 'Region'):\n",
    "                colourList.append(cl[i])\n",
    "            if i < len(g):\n",
    "                if (str(g[i]) == str(gniName)) and (attribute == 'GNI'):\n",
    "                    colourList.append(cl[i])\n",
    "    return RegionsList,colourList,gniList,happyList,devList\n",
    "\n",
    "# function that plots a 3d scatterplot of chosen features\n",
    "def plot_scatter(xvalues,yvalues,zvalues,REGIONS,GNI,HAPPY,DEV,attribute,Index1,Index2,Index3):\n",
    "    %matplotlib qt\n",
    "    fig = plt.figure(num=1)\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    if (attribute == 'Region'):\n",
    "        for j in range(len(r)):\n",
    "            index = []\n",
    "            index = [i for i, x in enumerate(REGIONS) if x == r[j]]\n",
    "            xx = [xvalues[x] for x in index]\n",
    "            yy = [yvalues[x] for x in index]\n",
    "            zz = [zvalues[x] for x in index]\n",
    "            ax.scatter(xx,yy,zz,label=r[j],color=cl[j])\n",
    "            ax.legend(loc='best')\n",
    "            ax.set_xlabel(IndicatorList[Index1])\n",
    "            ax.set_ylabel(IndicatorList[Index2])\n",
    "            ax.set_zlabel(IndicatorList[Index3])\n",
    "    if (attribute == 'GNI'):\n",
    "        for j in range(len(g)):\n",
    "            index = []\n",
    "            index = [i for i, x in enumerate(GNI) if x == g[j]]\n",
    "            xx = [xvalues[x] for x in index]\n",
    "            yy = [yvalues[x] for x in index]\n",
    "            zz = [zvalues[x] for x in index]\n",
    "            ax.scatter(xx,yy,zz,label=g[j],color=cl[j])\n",
    "            ax.legend(loc='upper left')\n",
    "            #ax.legend(loc='best')\n",
    "            ax.set_xlabel(IndicatorList[Index1])\n",
    "            ax.set_ylabel(IndicatorList[Index2])\n",
    "            ax.set_zlabel(IndicatorList[Index3])\n",
    "    if (attribute == 'Happy'):\n",
    "        for j in range(len(h)):\n",
    "            index = []\n",
    "            index = [i for i, x in enumerate(HAPPY) if x == h[j]]\n",
    "            xx = [xvalues[x] for x in index]\n",
    "            yy = [yvalues[x] for x in index]\n",
    "            zz = [zvalues[x] for x in index]\n",
    "            ax.scatter(xx,yy,zz,label=h[j],color=clh[j])\n",
    "            ax.legend(loc='best')\n",
    "            ax.set_xlabel(IndicatorList[Index1])\n",
    "            ax.set_ylabel(IndicatorList[Index2])\n",
    "            ax.set_zlabel(IndicatorList[Index3])\n",
    "    if (attribute == 'Dev'):\n",
    "        for j in range(len(d)):\n",
    "            index = []\n",
    "            index = [i for i, x in enumerate(DEV) if x == d[j]]\n",
    "            xx = [xvalues[x] for x in index]\n",
    "            yy = [yvalues[x] for x in index]\n",
    "            zz = [zvalues[x] for x in index]\n",
    "            ax.scatter(xx,yy,zz,label=d[j],color=cl[j])\n",
    "            ax.legend(loc='best')\n",
    "            ax.set_xlabel(IndicatorList[Index1])\n",
    "            ax.set_ylabel(IndicatorList[Index2]) \n",
    "            ax.set_zlabel(IndicatorList[Index3])\n",
    " \n",
    "# function that finds the most likely mapping of K-means labels to GNI or Region labels in dataset (thus to test accuracy\n",
    "# of K-means in classifying \"unseen\" test datapoints)\n",
    "\n",
    "def permutation_labels(q,attribute,Klabels,y_train):\n",
    "    per = list(permutations(range(len(q)))) \n",
    "    correctlabelslist = np.zeros((len(per)))\n",
    "    for i in range(len(per)):\n",
    "        labeldict = {per[i][c]:q[c] for c in range(len(q))}\n",
    "        KLabelPer = [labeldict.get(item,item)  for item in Klabels]\n",
    "        BothLabels = np.column_stack([KLabelPer,y_train]) \n",
    "        BothLabelsCompare = [BothLabels[c][0] == BothLabels[c][1] for c in range(len(BothLabels))]\n",
    "        CorrectLabels = (float(BothLabelsCompare.count(True))/float(len(y_train)))*100\n",
    "        correctlabelslist[i] = CorrectLabels\n",
    "    maxcorrect = np.argmax(correctlabelslist)\n",
    "    per = per[maxcorrect]\n",
    "    return per\n",
    "\n",
    "# function that finds accuracy of k-means in classifying test datapoints\n",
    "def K_means_test_accuracy(num,t_size,q,attribute,OUTPUT,xvalues,yvalues,zvalues,TestAccuracyMean,b,c):\n",
    "    testaccuracy = np.zeros((1,num))\n",
    "    km_precision = np.zeros((1,len(q)))\n",
    "    km_recall = np.zeros((1,len(q)))\n",
    "    km_f1 = np.zeros((1,len(q)))\n",
    "    km_num = np.zeros((1,len(q)))\n",
    "    for i in range(len(testaccuracy[0])):\n",
    "        Xinput = np.column_stack([np.array(xvalues),np.array(yvalues),np.array(zvalues)])\n",
    "        X_train, X_test, y_train, y_test = train_test_split(Xinput, OUTPUT, test_size=t_size, random_state=i)\n",
    "        #kmeans = KMeans(n_clusters=int(len(q)),random_state = c).fit(X_train)\n",
    "        kmeans = MiniBatchKMeans(n_clusters=int(len(q)),random_state=c).fit(X_train)\n",
    "        Klabels = kmeans.labels_\n",
    "        per = permutation_labels(q,attribute,Klabels,y_train)\n",
    "        labeldict = {per[c]:q[c] for c in range(len(q))}\n",
    "        y_pred = kmeans.predict(X_test)\n",
    "        y_pred = [labeldict.get(item,item)  for item in y_pred]\n",
    "        BothLabelstest = np.column_stack([y_pred,y_test]) \n",
    "        BothLabelsComparetest = [BothLabelstest[c][0] == BothLabelstest[c][1] for c in range(0,len(BothLabelstest))]\n",
    "        CorrectLabelstest = (float(BothLabelsComparetest.count(True))/float(len(y_test)))*100\n",
    "        testaccuracy[0,i] = CorrectLabelstest\n",
    "        report = classification_report(y_pred,y_test,target_names=q,labels=q,output_dict=True)\n",
    "        for v in range(len(q)):\n",
    "                km_precision[0,v] =  km_precision[0,v] + float(report[q[v]]['precision']) \n",
    "                km_recall[0,v] = km_recall[0,v] + float(report[q[v]]['recall'])    \n",
    "                km_f1[0,v] = km_f1[0,v] + float(report[q[v]]['f1-score'])\n",
    "                if float(report[q[v]]['precision'])>0:\n",
    "                    km_num[0,v] = km_num[0,v] + 1\n",
    "    for i in range(len(km_num)):\n",
    "        if int(km_num[0,i]) == 0:\n",
    "            km_num[i] = 1\n",
    "    k_p = np.divide(km_precision, km_num)\n",
    "    k_r = np.divide(km_recall, km_num)\n",
    "    k_f = np.divide(km_f1, km_num)\n",
    "    km_results = [k_p,k_r,k_f]\n",
    "    TestAccuracyMean[0,b] = np.mean(testaccuracy)\n",
    "    return TestAccuracyMean,km_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rearranged and merged datasets (using extra trees regression to predict missing values)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REARRANGE DATASETS IN ORDER TO USE EXTRA TREES REGRESSION TO PREDICT MISSING VALUES OF DATASET\n",
    "\n",
    "# Rearrange all Literacy Data\n",
    "LitData = get_recent_value(File,Indicator[0])\n",
    "for i in range(1,len(Indicator)):\n",
    "    LitCol = get_recent_value(File,Indicator[i])\n",
    "    LitData = LitData.merge(LitCol, left_index=True, right_index=True)\n",
    "LitData = LitData.iloc[:,1::2]\n",
    "\n",
    "# Rearrange all Politics Data\n",
    "PolData = get_recent_value(FileGen,IndicatorGen[0])\n",
    "for i in range(1,len(IndicatorGen)):\n",
    "    PolCol = get_recent_value(FileGen,IndicatorGen[i])\n",
    "    PolData = PolData.merge(PolCol, left_index=True, right_index=True)\n",
    "PolData = PolData.iloc[:,1::2]\n",
    "\n",
    "# Rearrange data in UnicefDatasets1\n",
    "Uni1Data = FileUnicef1.loc[FileUnicef1['Country'].isin(countries)]\n",
    "Uni1Data = Uni1Data.reset_index(inplace = False) \n",
    "Uni1Data = Uni1Data.iloc[:,6:]\n",
    "\n",
    "# merge all data together\n",
    "AllData = LitData.merge(PolData,left_index=True, right_index=True)\n",
    "AllData = AllData.merge(Uni1Data,left_index=True, right_index=True)\n",
    "\n",
    "# use random forest to predict all missing values in AllData\n",
    "imp = IterativeImputer(estimator=ExtraTreesRegressor(n_estimators=100, random_state=0),missing_values=np.nan,max_iter = 30, random_state=0)\n",
    "imp.fit(AllData)\n",
    "A = imp.transform(AllData)\n",
    "\n",
    "# reshape output back to shape of AllData\n",
    "X = A[:,0].reshape(len(countries),1)\n",
    "for i in range(1,len(A[0])):\n",
    "    B = A[:,i].reshape(len(countries),1)\n",
    "    X = np.column_stack((X,B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Correlations between features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlations and heatmap between features of all 3 datasets\n",
    "IndicatorList = np.array(Indicator)\n",
    "IndicatorList =  np.concatenate((IndicatorList, IndicatorGen), axis=None)\n",
    "IndicatorList = np.concatenate((IndicatorList, IndicatorUnicef1), axis=None)\n",
    "CORR = Correlation_features(X,IndicatorList)\n",
    "CORRELATION = CORR[0]\n",
    "SIGNIFICANCE = CORR[1]\n",
    "significant_correlations(CORRELATION,SIGNIFICANCE,IndicatorList)\n",
    "correlation_heatmap(CORRELATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3D Scatterplots between features of the 3 datasets (Literacy, Political and Unicef data)** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INDEX LIST OF FEATURES IN X:**\n",
    "\n",
    "0 --> 'Adult illiterate population, 15+ years, % female'\n",
    "\n",
    "1 --> 'Adult literacy rate, population 15+ years, gender parity index (GPI)'\n",
    "\n",
    "2 --> 'Learning poverty: gender difference (%)'\n",
    "\n",
    "3 --> 'Learning poverty: Share of Female Children at the End-of-Primary age below minimum reading proficiency adjusted by Out-of-School Children (%)'\n",
    "\n",
    "4 --> 'Learning poverty: Share of Male Children at the End-of-Primary age below minimum reading proficiency adjusted by Out-of-School Children (%)'\n",
    "\n",
    "5 --> 'Literacy rate, adult female (% of females ages 15 and above)'\n",
    "\n",
    "6 --> 'Literacy rate, adult gender difference (%)'\n",
    "\n",
    "7 --> 'Literacy rate, adult male (% of males ages 15 and above)'\n",
    "\n",
    "8 --> 'Literacy rate, youth (ages 15-24), gender parity index (GPI)'\n",
    "\n",
    "9 --> 'Literacy rate, youth female (% of females ages 15-24)'\n",
    "\n",
    "10 --> 'Literacy rate, youth gender difference (%)'\n",
    "\n",
    "11 --> 'Literacy rate, youth male (% of males ages 15-24)'\n",
    "\n",
    "12 --> 'Mean performance on the mathematics scale. Female'\n",
    "\n",
    "13 --> 'Mean performance on the mathematics scale. Gender Difference'\n",
    "\n",
    "14 --> 'Mean performance on the mathematics scale. Male'\n",
    "\n",
    "15 --> 'Mean performance on the reading scale. Female'\n",
    "\n",
    "16 --> 'Mean performance on the reading scale. Gender Difference'\n",
    "\n",
    "17 --> 'Mean performance on the reading scale. Male'\n",
    "\n",
    "18 --> 'Mean performance on the science scale. Female'\n",
    "\n",
    "19 --> 'Mean performance on the science scale. Gender Difference'\n",
    "\n",
    "20 --> 'Mean performance on the science scale. Male'\n",
    "\n",
    "21 --> 'Youth illiterate population, 15-24 years, % female'\n",
    "\n",
    "22 --> 'Youth illiterate population, 15-24 years, % male'\n",
    "\n",
    "23 --> 'Youth illiterate population, 15-24 years, gender difference (%)'\n",
    "\n",
    "24 --> 'Proportion of seats held by women in national parliaments (%)'\n",
    "\n",
    "25 --> 'Proportion of women in ministerial level positions (%)'\n",
    "\n",
    "26 --> 'Political Empowerment Score'\n",
    "\n",
    "27 --> 'Proportion of women in managerial positions'\n",
    "\n",
    "28 --> 'Proportion of women in senior and middle management positions'\n",
    "\n",
    "29 --> 'Share of female judges'\n",
    "\n",
    "30 --> 'Share of female police officers'\n",
    "\n",
    "31 --> 'Financial inclusion (%) - male'\n",
    "\n",
    "32 --> 'Financial inclusion (%) - female '\n",
    "\n",
    "33 --> 'Urban labour force participation rate (%) - male'\n",
    "\n",
    "34 --> 'Urban labour force participation rate (%) - female'\n",
    "\n",
    "35 --> 'Rural labour force participation rate (%) - male'\n",
    "\n",
    "36 --> 'Rural labour force participation rate (%) - female'\n",
    "\n",
    "37 --> 'Total labour force participation rate (%) - male'\n",
    "\n",
    "38 --> 'Total labour force participation rate (%) - female'\n",
    "\n",
    "39 --> 'Demand for family planning satisfied with modern methods (%) - Women aged 15-49'\n",
    "\n",
    "40 --> 'Demand for family planning satisfied with modern methods (%) - Women aged 15-19'\n",
    "\n",
    "41 --> 'Government Expenditure on Health as % of GDP'\n",
    "\n",
    "42 --> 'Government Expenditure on Education as % of GDP'\n",
    "\n",
    "43 --> 'Births by Age 18'\n",
    "\n",
    "44 --> 'Adolescent birth rate (number of live births to adolescent women per 1,000 adolescent women)'\n",
    "\n",
    "45 --> 'Percentage of adolescents (aged 10-14 years) engaged in household chores - male'\n",
    "\n",
    "46 --> 'Percentage of adolescents (aged 10-14 years) engaged in household chores - female'\n",
    "\n",
    "47 --> 'Percentage of boys (aged 15-17 years) who have experienced sexual violence'\n",
    "\n",
    "48 --> 'Percentage of girls (aged 15-17 years) who have experienced sexual violence'\n",
    "\n",
    "49 --> 'Percentage of women (aged 20-24 years) married or in union before age 15'\n",
    "\n",
    "50 --> 'Percentage of women (aged 20-24 years) married or in union before age 18'\n",
    "\n",
    "51 --> 'Percentage of women (aged 15-49 years) who consider a husband to be justified in hitting or beating his wife for at least one of the specified reasons'\n",
    "\n",
    "52 --> 'Happy Planet Index'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Selection for K-Means and K-NN --> selecting subset of feature combinations that best separate class labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce list of all feature combinations\n",
    "alllist = [Indicator,IndicatorGen,IndicatorUnicef1]\n",
    "n = int(len(Indicator))*int(len(IndicatorGen)+len(IndicatorUnicef1))*int(len(IndicatorGen)+len(IndicatorUnicef1))\n",
    "TestAccuracyMean = np.zeros((1,n))\n",
    "TestFeatures = np.zeros((3,n))\n",
    "a = 0\n",
    "CentroidSeparabilityList = []\n",
    "SilList = []\n",
    "for i in range(len(Indicator)):\n",
    "    for j in range(len(IndicatorGen)+len(IndicatorUnicef1)):\n",
    "        for k in range(len(IndicatorGen)+len(IndicatorUnicef1)):\n",
    "            TestFeatures[0,a] = i\n",
    "            TestFeatures[1,a] = int(len(Indicator)) + j\n",
    "            TestFeatures[2,a] = int(len(Indicator)) + k  \n",
    "            a = a + 1\n",
    "\n",
    "# Calculation of Centroid separation and Silhouette score of each feature combination \n",
    "scaler = StandardScaler()\n",
    "for i in range(n):\n",
    "    print(i)\n",
    "    Index1 = int(TestFeatures[0,i]) # First feature 0 to 23 \n",
    "    Index2 = int(TestFeatures[1,i]) # Second feature 24 to 52 \n",
    "    Index3 = int(TestFeatures[2,i]) # Third feature 52 to 52\n",
    "    attribute = 'Dev' #set to 'Region' or 'GNI' or 'Happy' or 'Dev'\n",
    "    xvalues = scaler.fit_transform(X[:,Index1].reshape(-1, 1))\n",
    "    yvalues = scaler.fit_transform(X[:,Index2].reshape(-1, 1))\n",
    "    zvalues = scaler.fit_transform(X[:,Index3].reshape(-1, 1))\n",
    "    RCG = get_regions_and_gni(File,FileUnicef1,r,g,h,d,cl,attribute)\n",
    "    REGIONS = RCG[0]\n",
    "    COLOUR = RCG[1]\n",
    "    GNI = RCG[2]\n",
    "    HAPPY = RCG[3]\n",
    "    DEV = RCG[4]\n",
    "    XXXX = np.column_stack([xvalues,yvalues,zvalues])\n",
    "    SilList.append(metrics.silhouette_score(XXXX, DEV, metric='sqeuclidean'))\n",
    "    Centroid = []\n",
    "    dist = 0\n",
    "    if (attribute == 'Region'):\n",
    "        for j in range(len(r)):\n",
    "            index = []\n",
    "            index = [i for i, x in enumerate(REGIONS) if x == r[j]]\n",
    "            xx = [xvalues[x] for x in index]\n",
    "            yy = [yvalues[x] for x in index]\n",
    "            zz = [zvalues[x] for x in index]\n",
    "            Centroid.append([np.mean(xx),np.mean(yy),np.mean(zz)])\n",
    "    if (attribute == 'GNI'):\n",
    "        for j in range(len(g)):\n",
    "            index = []\n",
    "            index = [i for i, x in enumerate(GNI) if x == g[j]]\n",
    "            xx = [xvalues[x] for x in index]\n",
    "            yy = [yvalues[x] for x in index]\n",
    "            zz = [zvalues[x] for x in index]\n",
    "            Centroid.append((np.mean(xx),np.mean(yy),np.mean(zz)))\n",
    "    if (attribute == 'Happy'):\n",
    "        for j in range(len(h)):\n",
    "            index = []\n",
    "            index = [i for i, x in enumerate(HAPPY) if x == h[j]]\n",
    "            xx = [xvalues[x] for x in index]\n",
    "            yy = [yvalues[x] for x in index]\n",
    "            zz = [zvalues[x] for x in index]\n",
    "            Centroid.append((np.mean(xx),np.mean(yy),np.mean(zz)))\n",
    "    if (attribute == 'Dev'):\n",
    "        for j in range(len(d)):\n",
    "            index = []\n",
    "            index = [i for i, x in enumerate(DEV) if x == d[j]]\n",
    "            xx = [xvalues[x] for x in index]\n",
    "            yy = [yvalues[x] for x in index]\n",
    "            zz = [zvalues[x] for x in index]\n",
    "            Centroid.append((np.mean(xx),np.mean(yy),np.mean(zz)))\n",
    "    for k in range(len(Centroid)):\n",
    "        for l in range(len(Centroid)):\n",
    "            dist = dist + float(distance.euclidean(Centroid[k],Centroid[l]))\n",
    "    CentroidSeparabilityList.append(dist)\n",
    "\n",
    "#Get rank of centroids\n",
    "GNIFEATURESCENTROID = CentroidSeparabilityList\n",
    "GNIFEATURESRANK = list(ss.rankdata(GNIFEATURESCENTROID))\n",
    "\n",
    "# top 200 combination of features in list\n",
    "TestFeaturesDev = np.zeros((3,200))\n",
    "aaa=0\n",
    "for i in range(len(GNIFEATURESRANK)):\n",
    "    if int(GNIFEATURESRANK[i])>(int(len(GNIFEATURESRANK))-200):\n",
    "        TestFeaturesDev[0,aaa] = int(TestFeatures[0,i])\n",
    "        TestFeaturesDev[1,aaa] = int(TestFeatures[1,i])\n",
    "        TestFeaturesDev[2,aaa] = int(TestFeatures[2,i])\n",
    "        aaa=aaa+1\n",
    "print(TestFeaturesDev)\n",
    "\n",
    "# Get rank of Silhouette scores\n",
    "GNIFEATURESCENTROID = SilList\n",
    "GNIFEATURESRANK = list(ss.rankdata(GNIFEATURESCENTROID))\n",
    "\n",
    "# top 200 combination of features in list\n",
    "TestFeaturesDevSil = np.zeros((3,200))\n",
    "aaa=0\n",
    "for i in range(len(GNIFEATURESRANK)):\n",
    "    if int(GNIFEATURESRANK[i])>(int(len(GNIFEATURESRANK))-200):\n",
    "        TestFeaturesDevSil[0,aaa] = int(TestFeatures[0,i])\n",
    "        TestFeaturesDevSil[1,aaa] = int(TestFeatures[1,i])\n",
    "        TestFeaturesDevSil[2,aaa] = int(TestFeatures[2,i])\n",
    "        aaa=aaa+1\n",
    "print(TestFeaturesDevSil)\n",
    "\n",
    "# Centroid: TestFeaturesHappy, TestFeaturesGNI, TestFeaturesRegion,TestFeaturesDev\n",
    "# Silhouette: TestFeaturesHappySil, TestFeaturesGNISil, TestFeaturesRegionSil,TestFeaturesDevSil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCATTERPLOTS \n",
    "# define features to plot and label attribute\n",
    "Index1 = 23 # First feature 0 to 23    \n",
    "Index2 = 44 # Second feature 24 to 30  \n",
    "Index3 = 52 # Third feature 31 to 52   \n",
    "attribute = 'Happy' #set to 'Region' or 'GNI' or 'Happy' or 'Dev'\n",
    "\n",
    "# define regions, gni and colours in plot\n",
    "r = File.Region.unique()\n",
    "g = File.GNI.unique()\n",
    "h = FileUnicef1.HPI_Class.unique()\n",
    "h = np.delete(h,3)\n",
    "d = FileUnicef1.Development.unique()\n",
    "cl = ['red','blue','green','orange','purple','cyan']\n",
    "clh = ['darkred','yellow','orange','green','red']\n",
    "# scaled x and y values to use in scatterplot (Using datset in X)\n",
    "scaler = StandardScaler()\n",
    "xvalues = scaler.fit_transform(X[:,Index1].reshape(-1, 1))\n",
    "yvalues = scaler.fit_transform(X[:,Index2].reshape(-1, 1))\n",
    "zvalues = scaler.fit_transform(X[:,Index3].reshape(-1, 1))\n",
    "RCG = get_regions_and_gni(File,FileUnicef1,r,g,h,d,cl,attribute)\n",
    "REGIONS = RCG[0]\n",
    "COLOUR = RCG[1]\n",
    "GNI = RCG[2]\n",
    "HAPPY = RCG[3]\n",
    "DEV = RCG[4]\n",
    "# plot scatter plot\n",
    "%matplotlib qt\n",
    "plot_scatter(xvalues,yvalues,zvalues,REGIONS,GNI,HAPPY,DEV,attribute,Index1,Index2,Index3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Centroid K-Means (3D - one feature from each dataset) - takes hours to run this code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# CENTROID K-MEANS OF ALL COMBINATIONS OF FEATURES FROM THE HDX, Happy Planet Index and UNICEF DATASETS\n",
    "\n",
    "alllist = [Indicator,IndicatorGen,IndicatorUnicef1]\n",
    "\n",
    "# initialise number of feature combinations and arrays\n",
    "#n = len(list(itertools.product(*alllist))) #all\n",
    "#TestAccuracyMean = np.zeros((1,n)) #all\n",
    "#TestFeatures = np.zeros((3,n)) #all\n",
    "#a = 0\n",
    "#for i in range(len(Indicator)):\n",
    "#    for j in range(len(IndicatorGen)):\n",
    "#        for k in range(len(IndicatorUnicef1)):\n",
    "#            TestFeatures[0,a] = i\n",
    "#            TestFeatures[1,a] = int(len(Indicator)) + j\n",
    "#            TestFeatures[2,a] = int(len(Indicator)) + int(len(IndicatorGen)) + k  \n",
    "#            a = a + 1\n",
    "TestFeatures = TestFeaturesDevSil # happy or gni or region or Dev\n",
    "n = int(len(TestFeatures[0]))\n",
    "TestAccuracyMean = np.zeros((1,n))\n",
    "\n",
    "\n",
    "# choose features for kmeans,initialise variables and compute test accuracy of each combination\n",
    "N = 1000 # number of times each combination of features is run\n",
    "TestAccuracyMeanList = np.zeros((N,n)) \n",
    "RCG = get_regions_and_gni(File,FileUnicef1,r,g,h,d,cl,attribute) # get labels for each country\n",
    "REGIONS = RCG[0]\n",
    "COLOUR = RCG[1]\n",
    "GNI = RCG[2]\n",
    "HAPPY = RCG[3]\n",
    "DEV = RCG[4]\n",
    "q = d # set q as either g (for GNI) or r (for Region) or h (for Happy) or d (for dev)\n",
    "OUTPUT = DEV # set as either GNI or REGIONS or HAPPY or DEV\n",
    "t_size = 0.2 # proportion of points in data split into test and training sets\n",
    "num = 5 # number of different splits of the data into test and training sets\n",
    "attribute = 'Dev' #set to 'Region' or 'GNI' or 'Happy' or 'Dev'\n",
    "scaler = StandardScaler()\n",
    "k_precision = np.zeros((n,len(q)))\n",
    "k_recall = np.zeros((n,len(q)))\n",
    "k_f1 = np.zeros((n,len(q)))\n",
    "for c in range(0,N):\n",
    "    print(c)\n",
    "    for b in range(0,n):\n",
    "        # initialise inputs\n",
    "        Index1 = int(TestFeatures[0,b]) # First feature 0 to 23\n",
    "        Index2 = int(TestFeatures[1,b]) # Second feature 24 to 30\n",
    "        Index3 = int(TestFeatures[2,b]) # Third feature 31 to 40\n",
    "        #Index1 = b\n",
    "        #Index2 = b\n",
    "        #Index3 = 52\n",
    "        InputMatrix = np.column_stack([X[:,Index1],X[:,Index2],X[:,Index3]])\n",
    "        InputMatrix = scaler.fit_transform(InputMatrix)\n",
    "        xvalues = InputMatrix[:,0]\n",
    "        yvalues = InputMatrix[:,1]\n",
    "        zvalues = InputMatrix[:,2]\n",
    "        TestMean,km_results = K_means_test_accuracy(num,t_size,q,attribute,OUTPUT,xvalues,yvalues,zvalues,TestAccuracyMean,b,c)\n",
    "        for v in range(len(q)):\n",
    "            k_precision[b][v] = k_precision[b][v] + km_results[0][0][v]\n",
    "            k_recall[b][v] = k_recall[b][v] + km_results[1][0][v]\n",
    "            k_f1[b][v] = k_f1[b][v] + km_results[2][0][v]\n",
    "    TestAccuracyMeanList[c,:] = TestAccuracyMean\n",
    "\n",
    "print('Mean Statistics:')\n",
    "print(np.divide(k_precision, float(N)))\n",
    "print(np.divide(k_recall, float(N)))\n",
    "print(np.divide(k_f1, float(N)))\n",
    "          \n",
    "# mean and standard deviation test accuracy for each combination\n",
    "FinalAccuracyMean= np.mean(TestAccuracyMeanList, axis=0) # mean accuracy of each combination of features\n",
    "FinalAccuracyStd = np.std(TestAccuracyMeanList, axis=0) # standard dev of test accuracy of each combination of features\n",
    "print(FinalAccuracyMean)\n",
    "print(FinalAccuracyStd)\n",
    "\n",
    "# combination that produces best results:\n",
    "MAX = np.max(FinalAccuracyMean)\n",
    "Maxindex = np.argmax(FinalAccuracyMean)\n",
    "STD = FinalAccuracyStd[int(Maxindex)]\n",
    "print(\"\\033[1m\" + \"Features that produce best results using K-Means clustering:\"+ \"\\033[0;0m\" + \"\\n\")\n",
    "print(IndicatorList[int(TestFeatures[0,Maxindex])] + \"\\n\")\n",
    "print(IndicatorList[int(TestFeatures[1,Maxindex])] + \"\\n\")\n",
    "print(IndicatorList[int(TestFeatures[2,Maxindex])] + \"\\n\")\n",
    "print(\"Mean Test Accuracy --> \" + str(MAX) + \"\\n\")\n",
    "print(\"std Test Accuracy --> \" + str(STD))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------**\n",
    "\n",
    "**DOES GENDER DATA EXHIBIT CLUSTERING RELATIONSHIP WITH OTHER DATA? CAN COUNTRIES WITH SIMILAR DEVELOPMENT/HAPPINESS BE GROUPED AND THUS DATA USED TO PREDICT WHAT DEVELOPMENT/HAPPINESS STAGE A COUNTRY IS AT?**\n",
    "\n",
    "**-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------**\n",
    "\n",
    "**Top 3 combination of features that produce best results using Centroid K-Means clustering (GNI):**\n",
    "\n",
    "**-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------**\n",
    "\n",
    "**Best:** Literacy rate, adult gender difference (%) (6),\n",
    "Financial inclusion (%) - male (31),\n",
    "Percentage of women (aged 15-49 years) who consider a husband to be justified in hitting or beating his wife for at least one of the specified reasons (51)\n",
    "\n",
    "**(Mean Test Accuracy --> 60.81944444444371%,                                 Standard Deviation Test Accuracy --> 1.69960635, Max test accuracy --> 63.88888889%)**\n",
    "\n",
    "**precision --> [L:0.62246889 UM:0.54792857 LM:0.33843611 H:0.72846946]**\n",
    " \n",
    "**recall --> [L:0.68813899 UM:0.51928673 LM:0.40885298 H:0.68754194]**\n",
    "\n",
    "**f1 --> [L:0.65365868 UM:0.5332233 LM:0.37032686  H:0.70741422]**\n",
    " \n",
    "**Second:** Mean performance on the science scale. Female (18),\n",
    "Financial inclusion (%) - female (32),\n",
    "Percentage of women (aged 15-49 years) who consider a husband to be justified in hitting or beating his wife for at least one of the specified reasons (51)\n",
    "\n",
    "**(Mean Test Accuracy --> 60.13277778%,                                 Standard Deviation Test Accuracy --> 2.28237199, Max test accuracy --> 66.11111111%)**\n",
    "\n",
    "**precision --> [L:0.7444     UM:0.52901714 LM:0.48178333 H:0.70979245]**\n",
    "\n",
    "**recall --> [L:0.61710646 UM:0.55331693 LM:0.394376   H:0.8180461 ]**\n",
    "\n",
    "**f1 --> [L:0.61710646 UM:0.54089425 LM:0.43371970 H:0.76008416]**\n",
    "\n",
    "**Third:** Mean performance on the science scale. Male (20),\n",
    "Financial inclusion (%) - female (32),\n",
    "Percentage of women (aged 15-49 years) who consider a husband to be justified in hitting or beating his wife for at least one of the specified reasons (51)\n",
    "\n",
    "**(Mean Test Accuracy --> 59.67%,                                 Standard Deviation Test Accuracy --> 2.07000656, Max test accuracy --> 64.44444444%)**\n",
    "\n",
    "**precision --> [L:0.747375   UM:0.53228857 LM:0.48140833 H:0.69003071]]**\n",
    "\n",
    "**recall --> [L:0.61772514 UM:0.54093311 LM:0.38289172 H:0.83437285]]**\n",
    "\n",
    "**f1 --> [L:0.67639334 UM:0.53657602 LM:0.42653535 H:0.75536807]**\n",
    "\n",
    "**-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------**\n",
    "\n",
    "**Top 3 combination of features that produce best results using Centroid K-Means clustering (Development):**\n",
    "\n",
    "**-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------**\n",
    "\n",
    "**Best:** Mean performance on the mathematics scale. Male (14),\n",
    "Financial inclusion (%) - male (31),\n",
    "Financial inclusion (%) - female (32)\n",
    "\n",
    "**(Mean Test Accuracy --> 67.61888889%,                                 Standard Deviation Test Accuracy --> 2.44319438, Max test accuracy --> 71.11111111%)**\n",
    "\n",
    "**precision --> [DEVELOPING:0.67481491 TRANSITION:0.50947143 DEVELOPED:0.79826097]**\n",
    "\n",
    "**recall --> [DEVELOPING:0.85678743 TRANSITION:0.32540213 DEVELOPED:0.68999161]**\n",
    "\n",
    "**f1 --> [DEVELOPING:0.75499092 TRANSITION:0.39714537 DEVELOPED:0.74018802]**\n",
    " \n",
    "**Second:** Mean performance on the reading scale. Male (17),\n",
    "Financial inclusion (%) - male (31),\n",
    "Financial inclusion (%) - female (32)\n",
    "\n",
    "**(Mean Test Accuracy --> 66.205%,                                 Standard Deviation Test Accuracy --> 2.94509631, Max test accuracy --> 70.55555556%)**\n",
    "\n",
    "**precision --> [DEVELOPING:0.6523092  TRANSITION:0.4524381  DEVELOPED:0.82264695]**\n",
    "\n",
    "**recall --> [DEVELOPING:0.86588576 TRANSITION:0.30246393 DEVELOPED:0.65607428]**\n",
    "\n",
    "**f1 --> [DEVELOPING:0.74407472  TRANSITION:0.36255355 DEVELOPED:0.72997870]**\n",
    "\n",
    "**Third:** Mean performance on the reading scale. Female (15),\n",
    "Financial inclusion (%) - male (31),\n",
    "Financial inclusion (%) - female (32)\n",
    "\n",
    "**(Mean Test Accuracy --> 64.67388889%,                                 Standard Deviation Test Accuracy --> 3.20668818, Max test accuracy --> 71.66666667%)**\n",
    "\n",
    "**precision --> [DEVELOPING:0.60243168 TRANSITION:0.48552476 DEVELOPED:0.85675688]**\n",
    "\n",
    "**recall --> [DEVELOPING:0.90177997 TRANSITION:0.30133487 DEVELOPED:0.63753933]**\n",
    "\n",
    "**f1 --> [DEVELOPING:0.72231965 TRANSITION:0.37187202 DEVELOPED:0.73106818]**\n",
    "\n",
    "**-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------**\n",
    "\n",
    "**Top 3 combination of features that produce best results using Centroid K-Means clustering (Development without Transition):**\n",
    "\n",
    "**-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------**\n",
    "\n",
    "**Best:** Mean performance on the mathematics scale. Female (12),\n",
    "Share of female judges (29),\n",
    "Government Expenditure on Health as % of GDP (41)\n",
    "\n",
    "**(Mean Test Accuracy --> 86.218%,                                 Standard Deviation Test Accuracy --> 0.375, Max test accuracy --> 87.222%)**\n",
    "\n",
    "**precision --> [DEVELOPED:0.92817668 DEVELOPING:0.84491398]**\n",
    "\n",
    "**recall --> [DEVELOPED:0.64592345 DEVELOPING:0.9670228 ]**\n",
    "\n",
    "**f1 --> [DEVELOPED:0.76874453 DEVELOPING:0.90185385]**\n",
    " \n",
    "**Second:** Mean performance on the mathematics scale. Male (14),\n",
    "Share of female police officers (30),\n",
    "Government Expenditure on Health as % of GDP (41) \n",
    "\n",
    "**(Mean Test Accuracy --> 85.624%,                                 Standard Deviation Test Accuracy --> 0.270, Max test accuracy --> 86.527%)**\n",
    "\n",
    "**precision --> [DEVELOPED:0.9061241  DEVELOPING:0.83881731]**\n",
    "\n",
    "**recall --> [DEVELOPED:0.63229579 DEVELOPING:0.96622098]**\n",
    "\n",
    "**f1 --> [DEVELOPED:0.74484015 DEVELOPING:0.89802292]**\n",
    "\n",
    "**Third:** Mean performance on the mathematics scale. Male (14),\n",
    "Share of female judges (29),\n",
    "Government Expenditure on Health as % of GDP (41)\n",
    "\n",
    "**(Mean Test Accuracy --> 85.557%,                                 Standard Deviation Test Accuracy --> 0.287, Max test accuracy --> 86.250%)**\n",
    "\n",
    "**precision --> [DEVELOPED:0.92777328 DEVELOPING:0.83645219]**\n",
    "\n",
    "**recall --> [DEVELOPED:0.63493852 DEVELOPING:0.96650218]**\n",
    "\n",
    "**f1 --> [DEVELOPED:0.75391891 DEVELOPING:0.89678682]**\n",
    "\n",
    "**-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------**\n",
    "\n",
    "**Top 3 combination of features that produce best results using Centroid K-Means clustering (Happiness):**\n",
    "\n",
    "**-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------**\n",
    "\n",
    "**Best:** Youth illiterate population, 15-24 years, % male (22),\n",
    "Government Expenditure on Education as % of GDP (42),\n",
    "Adolescent birth rate (number of live births to adolescent women per 1,000 adolescent women) (44)\n",
    "\n",
    "**(Mean Test Accuracy --> 45.389%,                                 Standard Deviation Test Accuracy --> 3.248, Max test accuracy --> 61.11111111%)**\n",
    "\n",
    "**precision --> [R:0.53233103 G:0.39365865 O:0.54271172 DO:0.54594553 Y:0.54771333]**\n",
    "\n",
    "**recall --> [R:0.71379628 G:0.40768622 O:0.22188818 DO:0.27159761 Y:0.61009079]**\n",
    "\n",
    "**f1 --> [R:0.60985086 G:0.40054965 O:0.31499171 DO:0.36273927 Y:0.57722174]**\n",
    "\n",
    "**Second:** Adult illiterate population, 15+ years, % female (0),\n",
    "Total labour force participation rate (%) - male (37),\n",
    "Demand for family planning satisfied with modern methods (%) - Women aged 15-49 (39)\n",
    "\n",
    "**(Mean Test Accuracy --> 45.200%,                                 Standard Deviation Test Accuracy --> 2.645, Max test accuracy --> 60.97222222%)**\n",
    "\n",
    "**precision --> [R:0.4610612  G:0.45272023 O:0.5084938  DO:0.53889022 Y:0.53336723]**\n",
    "\n",
    "**recall --> [R:0.57822793 G:0.26682704 O:0.30698016 DO:0.4448239  Y:0.64341243]**\n",
    "\n",
    "**f1 --> [R:0.51304003 G:0.33576112 O:0.38283873 DO:0.48735957 Y:0.58324445]**\n",
    "\n",
    "**Third:** Youth illiterate population, 15-24 years, gender difference (%) (23),\n",
    "Government Expenditure on Education as % of GDP (42),\n",
    "Adolescent birth rate (number of live births to adolescent women per 1,000 adolescent women) (44)\n",
    "\n",
    "**(Mean Test Accuracy --> 45.344%,                                 Standard Deviation Test Accuracy --> 3.381, Max test accuracy --> 60.27777778%)**\n",
    "\n",
    "**precision --> [R:0.53048149 G:0.39070005 O:0.53000936 DO:0.55200481 Y:0.54489156]**\n",
    "\n",
    "**recall --> [R:0.71161373 G:0.40683947 O:0.2205389  DO:0.2721589  Y:0.6097826 ]**\n",
    "\n",
    "**f1 --> [R:0.60784053 G:0.39860645 O:0.31147279  DO:0.36457082 Y:0.57551368]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**K-Nearest Neighbours**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_num_list = []\n",
    "K_mean_list = []\n",
    "K_std_list = []\n",
    "q = d # set q as either g (for GNI) or r (for Region) or h (for Happy) or d (for dev)\n",
    "OUTPUT = DEV # set as either GNI or REGIONS or HAPPY or DEV\n",
    "num = 5 # number of different splits of the data into test and training sets\n",
    "\n",
    "#TestFeatures = np.array([[],[],[]])\n",
    "#n=53\n",
    "TestFeatures = TestFeaturesDevSil\n",
    "n = int(len(TestFeatures[0]))\n",
    "for w in range(0,n):\n",
    "    print(w)\n",
    "    # define input variables and lists\n",
    "    xval = X[:,int(TestFeatures[0,w])]\n",
    "    yval = X[:,int(TestFeatures[1,w])]\n",
    "    zval = X[:,int(TestFeatures[2,w])]\n",
    "    #xval = X[:,w]\n",
    "    #yval = X[:,w]\n",
    "    #zval = X[:,52]\n",
    "    X_in = np.column_stack([xval,yval,zval])\n",
    "    k = list(range(1,50))\n",
    "    k_score_mean = []\n",
    "    k_score_std = []\n",
    "    F1_mean = []\n",
    "    kf = StratifiedKFold(n_splits=num, shuffle=False)\n",
    "    # compute mean test accuracy for number of neighbours, k, ranging from 1 to 100\n",
    "    for i in range(1,1+len(k)): \n",
    "        k_score = []\n",
    "        km_precision = np.zeros((1,len(q)))\n",
    "        km_recall = np.zeros((1,len(q)))\n",
    "        km_f1 = np.zeros((1,len(q)))\n",
    "        km_num = np.zeros((1,len(q)))\n",
    "        for j in range(0,num):\n",
    "            j_split = 0\n",
    "            for train_index, test_index in kf.split(X_in,OUTPUT):\n",
    "                if j == j_split:\n",
    "                    X_train, X_test = X[train_index], X[test_index]\n",
    "                    Y_train, Y_test = [OUTPUT[x] for x in train_index], [OUTPUT[x] for x in test_index]\n",
    "                j_split = j_split + 1\n",
    "            #X_train, X_test, Y_train, Y_test = train_test_split(X_in,DEV, test_size=0.2, random_state=j)\n",
    "            neigh = KNeighborsClassifier(n_neighbors=i)\n",
    "            neigh.fit(X_train, Y_train)\n",
    "            k_score.append(neigh.score(X_test,Y_test))\n",
    "            report = classification_report(neigh.predict(X_test),Y_test,target_names=q,labels=q,output_dict=True)\n",
    "            for v in range(len(q)):\n",
    "                km_precision[0,v] =  km_precision[0,v] + float(report[q[v]]['precision']) \n",
    "                km_recall[0,v] = km_recall[0,v] + float(report[q[v]]['recall'])    \n",
    "                km_f1[0,v] = km_f1[0,v] + float(report[q[v]]['f1-score'])\n",
    "                if float(report[q[v]]['precision'])>0:\n",
    "                    km_num[0,v] = km_num[0,v] + 1\n",
    "        for i in range(len(km_num)):\n",
    "            if int(km_num[0,i]) == 0:\n",
    "                km_num[i] = 1\n",
    "        #print('Mean Statistics:')\n",
    "        #print(q)\n",
    "        #print(np.divide(km_precision, km_num))\n",
    "        #print(np.divide(km_recall, km_num))\n",
    "        #print(np.divide(km_f1, km_num))\n",
    "        #print(np.max(k_score,axis=0))\n",
    "        F1_mean.append(np.mean(np.divide(km_recall, km_num)))\n",
    "        k_score_mean.append(mean(k_score))\n",
    "        k_score_std.append(stdev(k_score))\n",
    "    print(len(F1_mean))\n",
    "    print(np.max(k_score_mean))\n",
    "    print(np.nanmax(F1_mean))\n",
    "    K_mean_list.append(max(k_score_mean))\n",
    "    K_std_list.append(k_score_std[np.argmax(k_score_mean)])\n",
    "    K_num_list.append(int(np.argmax(k_score_mean))+1)\n",
    "    \n",
    "    \n",
    "print(K_mean_list)\n",
    "print(K_std_list)\n",
    "# plot number of neighbours vs mean test accuracy, print results\n",
    "plt.plot(k,k_score_mean)\n",
    "print(\"\\033[1m\" + \"Number of neighbours that produces highest test accuracy (GNI):\" + \"\\033[0;0m\")\n",
    "print(\"k = \" + str(int(np.argmax(k_score_mean)+1)))\n",
    "print(\"\\033[1m\" + \"Mean test accuracy using k = \" + str(int(np.argmax(k_score_mean))+1) + \" (GNI):\" + \"\\033[0;0m\")\n",
    "print(str(max(k_score_mean)))\n",
    "print(\"\\033[1m\" + \"Standard Deviation test accuracy using k = \" + str(np.argmax(k_score_mean)) + \" (GNI):\" + \"\\033[0;0m\")\n",
    "print(k_score_std[np.argmax(k_score_mean)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------**\n",
    "\n",
    "**DOES GENDER DATA EXHIBIT CLUSTERING RELATIONSHIP WITH OTHER DATA? CAN COUNTRIES WITH SIMILAR DEVELOPMENT/HAPPINESS BE GROUPED AND THUS DATA USED TO PREDICT WHAT DEVELOPMENT/HAPPINESS STAGE A COUNTRY IS AT?**\n",
    "\n",
    "**-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------**\n",
    "\n",
    "**Top 3 combination of features that produce best results using k-nearest neighbours (GNI):**\n",
    "\n",
    "**-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------**\n",
    "\n",
    "**Best:** Mean performance on the science scale. Male (20),\n",
    "Financial inclusion (%) - male (31)\n",
    "Percentage of women (aged 15-49 years) who consider a husband to be justified in hitting or beating his wife for at least one of the specified reasons (51)\n",
    "\n",
    "**(Mean Test Accuracy --> 61.056%,                                 Standard Deviation Test Accuracy --> 7.307, k = 27, Max test accuracy --> 86.111%)**\n",
    "\n",
    "**precision --> [L:0.7385934821241721, UM:0.5928655483405482, LM:0.3659460844710846, H:0.6752121468701577]**\n",
    "\n",
    "**recall --> [L:0.8385137748689231, UM:0.6314246074187244, LM:0.4357547494172491, H:0.533160606619043]**\n",
    "\n",
    "**f1 --> [L:0.785388319080233, UM:0.6115378684570987, LM:0.3978110976023557, H:0.5958368670302147]**\n",
    "\n",
    "**Second:** Mean performance on the mathematics scale. Male (14),\n",
    "Financial inclusion (%) - male (31)\n",
    "Percentage of women (aged 15-49 years) who consider a husband to be justified in hitting or beating his wife for at least one of the specified reasons (51)\n",
    "\n",
    "**(Mean Test Accuracy --> 61.0%,                                 Standard Deviation Test Accuracy --> 7.004, k = 21, Max test accuracy --> 86.111%)**\n",
    "\n",
    "**precision --> [L:0.733544379266245, UM:0.575518470418471, LM:0.39562351259851236, H:0.6633517406698914]**\n",
    "\n",
    "**recall --> [L:0.8206679653937408, UM:0.6241186147186146, LM:0.44807382062382034, H:0.539669005470122]**\n",
    "\n",
    "**f1 --> [L:0.7746642539892349, UM:0.5988340889970175, LM:0.4202183219937176, H:0.5951524532105283]**\n",
    "\n",
    "**Third:** Mean performance on the mathematics scale. Male (14),\n",
    "Percentage of women (aged 20-24 years) married or in union before age 15 (49)\n",
    "Percentage of women (aged 15-49 years) who consider a husband to be justified in hitting or beating his wife for at least one of the specified reasons (51)\n",
    "\n",
    "**(Mean Test Accuracy --> 60.722%,                                  Standard Deviation Test Accuracy --> 7.153, k = 16,Max test accuracy --> 86.111%)**\n",
    "\n",
    "**precision --> [L:0.7377874750593408, UM:0.6398099206349204, LM:0.4246830197580197, H:0.5940103056558159]**\n",
    "\n",
    "**recall --> [L:0.8250444013502857, UM:0.6388209568209557, LM:0.42744247704909477, H:0.5385179359039654]**\n",
    "\n",
    "**f1 --> [L:0.7789800488104802, UM:0.6393150562682921, LM:0.4260582803970431, H:0.5649045948150304]**\n",
    "\n",
    "**-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------**\n",
    "\n",
    "**Top 3 combination of features that produce best results using k-nearest neighbours (Development):**\n",
    "\n",
    "**-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------**\n",
    "\n",
    "**Best:** Mean performance on the mathematics scale. Female (12),\n",
    "Share of female judges (%) (29),\n",
    "Financial inclusion (%) - female (32)\n",
    "\n",
    "**(Mean Test Accuracy --> 83.858%,                                 Standard Deviation Test Accuracy --> 5.6543, k = 2, Max test accuracy --> 100%)**\n",
    "\n",
    "**precision --> [DEVELOPING:0.9059963954123553, TRANSITION:0.1695273809523809, DEVELOPED:0.9227963508713525]**\n",
    "\n",
    "**recall  --> [DEVELOPING:0.8939461668180482, TRANSITION:0.48723333333333335, DEVELOPED:0.7047506713874373]**\n",
    "\n",
    "**f1  --> [DEVELOPING:0.899930944269954, TRANSITION:0.2515357240955942, DEVELOPED:0.7991675066049854]**\n",
    "\n",
    "**Second:** Learning poverty: Share of Male Children at the End-of-Primary age below minimum reading proficiency adjusted by Out-of-School Children (%) (4),\n",
    "Share of female judges (%) (29),\n",
    "Percentage of women (aged 15-49 years) who consider a husband to be justified in hitting or beating his wife for at least one of the specified reasons (51)\n",
    "\n",
    "**(Mean Test Accuracy --> 83.489%,                                 Standard Deviation Test Accuracy --> 5.5784, k = 21, Max test accuracy --> 100%)**\n",
    "\n",
    "**precision --> [DEVELOPING:0.9093857917040175, TRANSITION:0.0, DEVELOPED:0.9631083638583653]**\n",
    "\n",
    "**recall --> [DEVELOPING:0.889100223576146, TRANSITION:0.0, DEVELOPED:0.7055588641750412]**\n",
    "\n",
    "**f1  --> [DEVELOPING:0.8991286046725929, TRANSITION:0.0, DEVELOPED:0.8144579480742178]**\n",
    "\n",
    "**Third:** Mean performance on the mathematics scale. Female (12),\n",
    "Proportion of women in ministerial level positions (%) (25),\n",
    "Share of female judges (%) (29)\n",
    "\n",
    "**(Mean Test Accuracy --> 83.056%,                                 Standard Deviation Test Accuracy --> 5.8246, k = 4, Max test accuracy --> 100%)**\n",
    "\n",
    "**precision  --> [DEVELOPING:0.9093093392516309, TRANSITION:0.0833130952380953, DEVELOPED:0.8997294566544585]**\n",
    "\n",
    "**recall  --> [DEVELOPING:0.8696603748436059, TRANSITION:0.2121666666666667, DEVELOPED:0.7356410336051991]**\n",
    "\n",
    "**f1  --> [DEVELOPING:0.8890430169291013, TRANSITION:0.11964448321199454, DEVELOPED:0.8094531623268311]**\n",
    "\n",
    "**-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------**\n",
    "\n",
    "**Top 3 combination of features that produce best results using k-nearest neighbours (Development without transition):**\n",
    "\n",
    "**-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------**\n",
    "\n",
    "**Best:** Learning poverty: Share of Male Children at the End-of-Primary age below minimum reading proficiency adjusted by Out-of-School Children (%) (4),\n",
    "Proportion of women in ministerial level positions (%) (25),\n",
    "Government Expenditure on Health as % of GDP (41)\n",
    "\n",
    "**(Mean Test Accuracy --> 91.363%,                                 Standard Deviation Test Accuracy --> 4.1692, k = 9, Max test accuracy --> 100%)**\n",
    "\n",
    "**precision --> [DEVELOPED:0.82124178 DEVELOPING:0.94032703]**\n",
    "\n",
    "**recall  --> [DEVELOPED:0.79540259 DEVELOPING:0.94941078]**\n",
    "\n",
    "**f1  --> [DEVELOPED:0.8081156882118858  DEVELOPING:0.9448470727347974]**\n",
    "\n",
    "**Second:** Mean performance on the mathematics scale. Female (12),\n",
    "Proportion of women in ministerial level positions (%) (25),\n",
    "Financial inclusion (%) - female (32)\n",
    "\n",
    "**(Mean Test Accuracy --> 90.755%,                                 Standard Deviation Test Accuracy --> 4.3742, k = 3, Max test accuracy --> 100%)**\n",
    "\n",
    "**precision --> [DEVELOPED:0.8203595  DEVELOPING:0.93337754]**\n",
    "\n",
    "**recall --> [DEVELOPED:0.77687984 DEVELOPING:0.94828162]**\n",
    "\n",
    "**f1  --> [DEVELOPED:0.7980278736466384 DEVELOPING:0.9407705545384902]**\n",
    "\n",
    "**Third:** Mean performance on the mathematics scale. Female (12),\n",
    "Proportion of women in ministerial level positions (%) (25),\n",
    "Government Expenditure on Health as % of GDP (41)\n",
    "\n",
    "**(Mean Test Accuracy --> 90.531%,                                 Standard Deviation Test Accuracy --> 4.5679, k = 4, Max test accuracy --> 100%)**\n",
    "\n",
    "**precision  --> [DEVELOPED:0.89919376 DEVELOPING:0.90836998]**\n",
    "\n",
    "**recall  --> [DEVELOPED:0.73320163 DEVELOPING:0.96919523]**\n",
    "\n",
    "**f1  --> [DEVELOPED:0.8077581382018345 DEVELOPING:0.937797363310961]**\n",
    "\n",
    "**-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------**\n",
    "\n",
    "**Top 3 combination of features that produce best results using k-nearest neighbours (Happiness):**\n",
    "\n",
    "**-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------**\n",
    "\n",
    "**Best:** Youth illiterate population, 15-24 years, gender difference (%) (23),\n",
    "Adolescent birth rate (number of live births to adolescent women per 1,000 adolescent women) (44),\n",
    "Happy Planet Index (52)\n",
    "\n",
    "**(Mean Test Accuracy --> 58.850%,                                 Standard Deviation Test Accuracy --> 7.3446, k = 9, Max test accuracy --> 86.111%)**\n",
    "\n",
    "**precision --> [R:0.70657897 G:0.30307999 O:0.38106061 DO:0.48368878 Y:0.85958478]**\n",
    "\n",
    "**recall --> [R:0.68806248 G:0.83905386 O:0.58939394 DO:0.70522114 Y:0.58629164]**\n",
    "\n",
    "**f1 --> [R:0.6971978043733688 G:0.4453075889454838 O:0.46286518890906003 DO:0.5738156391811572 Y:0.6971098821643957]**\n",
    "\n",
    "**Second:** Adult illiterate population, 15+ years, % female (0),\n",
    "Adolescent birth rate (number of live births to adolescent women per 1,000 adolescent women) (44),\n",
    "Happy Planet Index (52)\n",
    "\n",
    "**(Mean Test Accuracy --> 58.811%,                                 Standard Deviation Test Accuracy --> 7.3453, k = 7, Max test accuracy --> 83.333%)**\n",
    "\n",
    "**precision --> [R:0.66774055 G:0.31498042 O:0.43751468 DO:0.4707125  Y:0.88066393]**\n",
    "\n",
    "**recall --> [R:0.66915117 G:0.57572559 O:0.75467385 DO:0.60798379 Y:0.60181621]**\n",
    "\n",
    "**f1 --> [R:0.6684451157928385 G:0.40718775018245984 O:0.5539071710195333  DO:0.5306138018707287 Y:0.7150150809255432]**\n",
    "\n",
    "**Third:** Adult illiterate population, 15+ years, % female (0),\n",
    "Adolescent birth rate (number of live births to adolescent women per 1,000 adolescent women) (44),\n",
    "Percentage of women (aged 15-49 years) who consider a husband to be justified in hitting or beating his wife for at least one of the specified reasons (51)\n",
    "\n",
    "**(Mean Test Accuracy --> 58.655%,                                 Standard Deviation Test Accuracy --> 7.4080, k = 6, Max test accuracy --> 83.333%)**\n",
    "\n",
    "**precision --> [R:0.69728656 G:0.29970238 O:0.42245442 DO:0.5553407  Y:0.84261763]**\n",
    "\n",
    "**recall --> [R:0.68271083 G:0.62473958 O:0.82927619 DO:0.54864068 Y:0.59916277]**\n",
    "\n",
    "**f1 --> [R:0.6899217195265055 G:0.4050788413070311  O:0.559755252555915 DO:0.5519703589197782 Y:0.7003356589417294]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
